Semana 6: Variables Aleatorias (V.A.), Valor Esperado y Varianza
Conceptos Clave
â€¢ Variable Aleatoria (V.A.): FunciÃ³n que transforma un experimento aleatorio en un nÃºmero real. Se denotan con mayÃºsculas (X, Y) y valores en minÃºsculas (x, y).
â€¢ Recorrido (o Soporte): Conjunto de todos los valores posibles que puede tomar la V.A. (R_x).
  - V.A. Discreta: Recorrido finito o infinito numerable.
  - V.A. Continua: Recorrido en un intervalo de nÃºmeros reales.
â€¢ FunciÃ³n de Masa de Probabilidad (FMP): Para v.a. discreta X â†’ f(x) = P(X = x). Debe cumplir f(x) â‰¥ 0 y Î£ f(x) = 1.
â€¢ FunciÃ³n de Densidad de Probabilidad (FDP): Para v.a. continua X â†’ f(x). Debe cumplir f(x) â‰¥ 0 y âˆ« f(x) dx = 1.
FÃ³rmulas
â€¢ Valor Esperado (E[X]):
   - Discreta:   E(X) = Î£ (x â‹… f(x))
   - Continua:   E(X) = âˆ« x â‹… f(x) dx
â€¢ Varianza (Var[X]): Var(X) = E[(X âˆ’ E(X))^2] = E(X^2) âˆ’ [E(X)]^2
CÃ³digo en R

# Ejemplo: Para f(x) = 0.075x + 0.2 si 3 â‰¤ x â‰¤ 5, calcular P(3 â‰¤ X â‰¤ 4)
f <- function(x) { 0.075 * x + 0.2 }
probabilidad <- integrate(f, lower = 3, upper = 4)
print(probabilidad$value)
ðŸ‘‰ Trucos: Siempre verificar que la integral de la FDP en todo el dominio sea igual a 1.
Semana 7: Distribuciones Discretas
Conceptos Clave
â€¢ Bernoulli: Modela un ensayo con dos resultados (Ã©xito/fracaso).
â€¢ Binomial: NÃºmero de Ã©xitos en n ensayos de Bernoulli.
â€¢ Poisson: NÃºmero de eventos en un intervalo de tiempo/espacio.
FÃ³rmulas
â€¢ Bernoulli: f(x) = p^x (1-p)^(1-x),  E(X)=p,  Var(X)=p(1-p)
â€¢ Binomial: f(x) = (nCx) p^x (1-p)^(n-x),  E(X)=np,  Var(X)=np(1-p)
â€¢ Poisson: f(x) = (Î»^x e^(âˆ’Î»)) / x!,  E(X)=Î»,  Var(X)=Î»


Ejemplo Resuelto (Binomial)

ðŸ“Œ Problema: La probabilidad de que un estudiante termine la carrera es p = 0.3.
Se matriculan n = 7. Calcular:

La probabilidad de que todos terminen.

La probabilidad de que al menos 2 terminen.

âœ… Planteamiento:

Caso 1: P(X=7)

Caso 2: P(Xâ‰¥2) = 1 âˆ’ P(Xâ‰¤1)

âœ… ResoluciÃ³n manual:

P(X=7) = (7C7)(0.3^7)(0.7^0) = 0.0002187

P(Xâ‰¤1) = P(X=0) + P(X=1) = (7C0)(0.3^0)(0.7^7) + (7C1)(0.3^1)(0.7^6)
= 0.0823543 + 0.247063 = 0.329417

P(Xâ‰¥2) = 1 âˆ’ 0.329417 = 0.670583
ðŸ‘‰ Trucos: Para calcular 'al menos', se usa el complemento: P(X â‰¥ k) = 1 âˆ’ P(X â‰¤ kâˆ’1).
âœ… CÃ³digo en R:

n <- 7; p <- 0.3
prob_todos <- dbinom(7, size=n, prob=p)
prob_al_menos_2 <- 1 - pbinom(1, size=n, prob=p)

print(prob_todos)
print(prob_al_menos_2)

ðŸ‘‰ Truco: En binomial, cuando p es muy pequeÃ±a y n muy grande, se aproxima con Poisson: X ~ Poisson(Î» = np).

Semana 8: Distribuciones Continuas
Conceptos Clave
â€¢ Uniforme Continua: Todos los valores en [a,b] tienen igual probabilidad.
â€¢ Exponencial: Tiempo entre eventos de Poisson.

â€¢ Normal: DistribuciÃ³n en forma de campana, caracterizada por Î¼ y ÏƒÂ².
FÃ³rmulas

â€¢ Uniforme: f(x)=1/(bâˆ’a),  E(X)=(a+b)/2,  Var(X)=(bâˆ’a)^2/12

â€¢ Exponencial: f(x)=Î»e^(âˆ’Î»x),  E(X)=1/Î»,  Var(X)=1/Î»^2

â€¢ Normal: f(x)=(1/(âˆš(2Ï€Ïƒ^2))) e^(âˆ’(xâˆ’Î¼)^2 / (2Ïƒ^2)),  X~N(Î¼,Ïƒ^2)

Ejemplo Resuelto (Normal)

ðŸ“Œ Problema: El ancho de rollos de tela sigue una distribuciÃ³n normal con media Î¼=950 mm y desviaciÃ³n estÃ¡ndar Ïƒ=10 mm. Calcular:

P(947 â‰¤ X â‰¤ 958)

El valor C tal que P(X < C) = 0.8531

âœ… Planteamiento:

Normal(950, 10^2).

Se usan probabilidades acumuladas con pnorm.

âœ… ResoluciÃ³n manual (estandarizaciÃ³n):

ð‘=(ð‘‹âˆ’ðœ‡)/ðœŽ


P(947 â‰¤ X â‰¤ 958) = P(âˆ’0.3 â‰¤ Z â‰¤ 0.8) = Î¦(0.8) âˆ’ Î¦(âˆ’0.3) â‰ˆ 0.7881 âˆ’ 0.3821 = 0.406

Buscar C: P(X < C)=0.8531 â†’ P(Z < z)=0.8531 â†’ z=1.05 â†’ C=950+1.05(10)=960.5

âœ… CÃ³digo en R:

media <- 950; desv_estandar <- 10
prob_947_958 <- pnorm(958, mean=media, sd=desv_estandar) - pnorm(947, mean=media, sd=desv_estandar)
valor_c <- qnorm(0.8531, mean=media, sd=desv_estandar)

print(prob_947_958)
print(valor_c)


ðŸ‘‰ Truco: Cuando se pide un cuantil, usar qnorm. Cuando se pide probabilidad acumulada, usar pnorm.


Semana 9: Distribuciones Multivariadas
Conceptos Clave
â€¢ FunciÃ³n de Probabilidad Conjunta: p(y1,y2)=P(Y1=y1,Y2=y2)
â€¢ Densidad Conjunta: f(y1,y2) en el caso continuo.
â€¢ Probabilidades marginales: Se obtienen integrando o sumando sobre la otra variable.
â€¢ Independencia: f(y1,y2) = f1(y1) * f2(y2)
â€¢ Valor esperado de g(Y1,Y2): E[g(Y1,Y2)] = Î£Î£ g(y1,y2) p(y1,y2)  (discreta), o E[g(Y1,Y2)] = âˆ«âˆ« g(y1,y2) f(y1,y2) dy1dy2 (continua).


ðŸ”¹ Semana 9: Distribuciones Multivariadas
Conceptos Clave

Conjunta: f(y1,y2)

Marginales: integraciÃ³n/suma sobre la otra variable.

Independencia: f(y1,y2)=f1(y1)f2(y2).

Ejemplo Resuelto

ðŸ“Œ Problema: Sea la densidad conjunta

ð‘“(ð‘¦1,ð‘¦2)=2ð‘¦1 enÂ elÂ cuadradoÂ unitarioÂ [0,1]Ã—[0,1].


Calcular el valor esperado E(Y1Â·Y2).

âœ… Planteamiento:

ð¸(ð‘Œ1ð‘Œ2)=âˆ«01âˆ«01(ð‘¦1â‹…ð‘¦2)(2ð‘¦1)ð‘‘ð‘¦1ð‘‘ð‘¦2

E(Y1Y2)=âˆ«01	âˆ«01
	â€‹



âœ… ResoluciÃ³n manual:

Integral interna: âˆ« (2y1^2 y2) dy1 = (2/3)y1^3 y2 |0^1 = (2/3)y2

Integral externa: âˆ« (2/3)y2 dy2 = (2/3)(1/2)=1/3

âœ… CÃ³digo en R:

valor_esperado <- 1/3
print(valor_esperado)


ðŸ‘‰ Truco: Si las variables son independientes, E(Y1Y2)=E(Y1)E(Y2), lo cual simplifica mucho.

ðŸ‘‰ Trucos: Si las variables son independientes, se pueden separar las integrales para simplificar.
